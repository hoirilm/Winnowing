Text is often found in various places such as street names, shop names, banners, road guides, warnings, and so on. Text detection is divided into three approaches namely texture approach, edge approach, and connected component approach. The texture approach can detect text well, but requires a lot of training data. Text localization is a basic step in many computer applications including Video Optical Character Recognition (OCR), to understand video content, and so on. This study aims to localize text in images. The method used in this study is Directional Discrete Cosine Transform (DDCT) and connected components. The dataset used is the ICDAR2013 Focused Scene Text Robust Reading Competition dataset which has 233 data in the test data. The results obtained with the average value of this study were precision 0.36, recall 0.91 and f1 score 0.45. The precision value is lower because many non-text components are localized. Whereas the recall value is higher and many texts are localized.